# æ€è€ƒæ¨¡å‹é…ç½®æŒ‡å—

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

æ”¯æŒä¸åŒ AI æä¾›å•†çš„æ€è€ƒæ¨¡å‹ï¼ˆReasoning Modelsï¼‰ï¼ŒåŒ…æ‹¬ï¼š
- **é€šç”¨**: ä¸ºæ‰€æœ‰æ¨¡å‹æ·»åŠ  `stream_options` ç”¨äºè®¡è´¹è¿½è¸ª
- **æ™ºè°± AI (GLM)**: Binary æ¨¡å¼ï¼ˆå¯ç”¨/ç¦ç”¨æ€è€ƒï¼‰
- **åƒé—® (Qwen)**: Binary æ¨¡å¼ï¼ˆå¯ç”¨/ç¦ç”¨æ€è€ƒï¼‰
- **è±†åŒ… (Doubao) / DeepSeek**: Levels æ¨¡å¼ï¼ˆå››æ¡£æ€è€ƒå¼ºåº¦ï¼‰

## ğŸ“‹ é€šç”¨é…ç½®

### stream_options - ç”¨äºè®¡è´¹

**æ‰€æœ‰æ¨¡å‹**åœ¨æµå¼è¯·æ±‚æ—¶éƒ½éœ€è¦æ·»åŠ ï¼š

```json
{
  "stream": true,
  "stream_options": {
    "include_usage": true
  }
}
```

è¿™ä¸ªå‚æ•°ç”¨äºè¿½è¸ª token ä½¿ç”¨é‡ï¼Œä»¥ä¾¿è®¡è´¹ã€‚

## ğŸ§  æ€è€ƒæ¨¡å‹å‚æ•°æ ¼å¼

### 1. æ™ºè°± AI (GLM) - Binary Mode

**å‚æ•°æ ¼å¼**:
```json
{
  "thinking": {
    "type": "enabled"  // æˆ– "disabled"
  }
}
```

**æ¨¡å‹é…ç½®**:
- `is_reasoning_model`: 1
- `reasoning_type`: `'binary'`
- `default_reasoning_effort`: `'enabled'` æˆ– `'disabled'`

**UI æ˜¾ç¤º**: äºŒé€‰ä¸€å¼€å…³
- ç¦ç”¨æ€è€ƒ
- å¯ç”¨æ€è€ƒ

### 2. åƒé—® (Qwen) - Binary Mode

**å‚æ•°æ ¼å¼**:
```json
{
  "enable_thinking": true  // æˆ– false
}
```

**API ç¤ºä¾‹**:
```bash
curl -X POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \
-H "Authorization: Bearer $DASHSCOPE_API_KEY" \
-H "Content-Type: application/json" \
-d '{
    "model": "qwen-plus",
    "messages": [{"role": "user", "content": "ä½ æ˜¯è°"}],
    "stream": true,
    "stream_options": {"include_usage": true},
    "enable_thinking": true
}'
```

**æ¨¡å‹é…ç½®**:
- `is_reasoning_model`: 1
- `reasoning_type`: `'binary'`
- `default_reasoning_effort`: `'enabled'` æˆ– `'disabled'`

**UI æ˜¾ç¤º**: äºŒé€‰ä¸€å¼€å…³
- ç¦ç”¨æ€è€ƒ
- å¯ç”¨æ€è€ƒ

### 3. è±†åŒ… (Doubao) / DeepSeek - Levels Mode

**å‚æ•°æ ¼å¼**:
```json
{
  "reasoning_effort": "medium"  // minimal/low/medium/high
}
```

**æ¨¡å‹é…ç½®**:
- `is_reasoning_model`: 1
- `reasoning_type`: `'levels'`
- `default_reasoning_effort`: `'minimal'` / `'low'` / `'medium'` / `'high'`

**UI æ˜¾ç¤º**: å››æ¡£é€‰æ‹©å™¨
- Minimal (ä¸æ€è€ƒ)
- Low (ä½)
- Medium (ä¸­)
- High (é«˜)

## ğŸ’» æŠ€æœ¯å®ç°

### æ•°æ®åº“è¡¨ç»“æ„ (models)

```sql
CREATE TABLE models (
  id TEXT PRIMARY KEY,
  provider_id TEXT NOT NULL,
  name TEXT NOT NULL,
  is_reasoning_model INTEGER DEFAULT 0,
  reasoning_type TEXT DEFAULT 'levels',  -- 'binary' or 'levels'
  default_reasoning_effort TEXT DEFAULT 'medium',
  sort_order INTEGER DEFAULT 0,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (provider_id) REFERENCES providers(id)
);
```

### å½“å‰é…ç½®

| Provider | Model | is_reasoning | reasoning_type | default_reasoning_effort |
|----------|-------|--------------|----------------|-------------------------|
| zhipu | glm-zero-preview | 1 | binary | enabled |
| qwen | qwen-plus | 1 | binary | enabled |
| qwen | qwen3-max | 1 | binary | enabled |
| deepseek | deepseek-reasoner | 1 | levels | medium |
| doubao | doubao-seed-* | 1 | levels | medium |

### æ ¸å¿ƒä»£ç é€»è¾‘

#### lib/ai.ts - è¯·æ±‚æ‹¦æˆªå™¨

```typescript
const createLoggingFetch = (providerId: string, reasoningEffort?: string) => {
  return async (url: string | URL | Request, init?: RequestInit) => {
    if (init?.body) {
      const bodyJson = JSON.parse(bodyString);
      
      // 1. ä¸ºæ‰€æœ‰æµå¼è¯·æ±‚æ·»åŠ  usage tracking
      if (bodyJson.stream) {
        bodyJson.stream_options = {
          include_usage: true
        };
        console.log('âœ… Added stream_options for usage tracking');
      }
      
      // 2. æ ¹æ® provider æ·»åŠ æ€è€ƒå‚æ•°
      if (reasoningEffort) {
        switch (providerId) {
          case 'zhipu':
            // GLM ä½¿ç”¨ thinking å‚æ•°
            bodyJson.thinking = { 
              type: reasoningEffort === 'disabled' ? 'disabled' : 'enabled'
            };
            console.log(`âœ… Injected thinking (${bodyJson.thinking.type}) for GLM model`);
            break;
          
          case 'qwen':
            // åƒé—®ä½¿ç”¨ enable_thinking å‚æ•°
            bodyJson.enable_thinking = reasoningEffort !== 'disabled' && reasoningEffort !== 'minimal';
            console.log(`âœ… Injected enable_thinking (${bodyJson.enable_thinking}) for Qwen model`);
            break;
          
          case 'doubao':
          case 'deepseek':
          default:
            // å…¶ä»–æä¾›å•†ä½¿ç”¨ reasoning_effort å‚æ•°
            bodyJson.reasoning_effort = reasoningEffort;
            console.log('âœ… Injected reasoning_effort:', reasoningEffort);
            break;
        }
      }
      
      init = { ...init, body: JSON.stringify(bodyJson) };
    }
    
    return fetch(url, init);
  };
};
```

#### components/chat/reasoning-effort-selector.tsx - UI ç»„ä»¶

```tsx
export function ReasoningEffortSelector({ 
  reasoningEffort, 
  setReasoningEffort,
  reasoningType = 'levels'
}: Props) {
  return (
    <ToggleGroup type="single" value={reasoningEffort} onValueChange={setReasoningEffort}>
      {reasoningType === 'binary' ? (
        <>
          <ToggleGroupItem value="disabled">ç¦ç”¨æ€è€ƒ</ToggleGroupItem>
          <ToggleGroupItem value="enabled">å¯ç”¨æ€è€ƒ</ToggleGroupItem>
        </>
      ) : (
        <>
          <ToggleGroupItem value="minimal">Minimal</ToggleGroupItem>
          <ToggleGroupItem value="low">Low</ToggleGroupItem>
          <ToggleGroupItem value="medium">Medium</ToggleGroupItem>
          <ToggleGroupItem value="high">High</ToggleGroupItem>
        </>
      )}
    </ToggleGroup>
  );
}
```

## ğŸ” è°ƒè¯•æ–¹æ³•

### æŸ¥çœ‹ç»ˆç«¯æ—¥å¿—

å‘é€æ¶ˆæ¯æ—¶ï¼Œç»ˆç«¯ä¼šæ‰“å°ï¼š

```
=== AI SDK HTTP Request ===
URL: https://...
Method: POST
Request Body: {
  "model": "qwen-plus",
  "messages": [...],
  "stream": true,
  "stream_options": {"include_usage": true},  âœ… æ‰€æœ‰æ¨¡å‹éƒ½æœ‰
  "enable_thinking": true  âœ… åƒé—®ç‰¹æœ‰
}
=== End Request ===

âœ… Added stream_options for usage tracking
âœ… Injected enable_thinking (true) for Qwen model
```

### æµ‹è¯•éªŒè¯æ¸…å•

- [ ] **GLM æ¨¡å‹**
  - [ ] é€‰æ‹©"ç¦ç”¨æ€è€ƒ" â†’ æ—¥å¿—æ˜¾ç¤º `thinking (disabled)`
  - [ ] é€‰æ‹©"å¯ç”¨æ€è€ƒ" â†’ æ—¥å¿—æ˜¾ç¤º `thinking (enabled)`
  - [ ] è¯·æ±‚ä½“åŒ…å« `"thinking": {"type": "..."}`

- [ ] **åƒé—®æ¨¡å‹**
  - [ ] é€‰æ‹©"ç¦ç”¨æ€è€ƒ" â†’ æ—¥å¿—æ˜¾ç¤º `enable_thinking (false)`
  - [ ] é€‰æ‹©"å¯ç”¨æ€è€ƒ" â†’ æ—¥å¿—æ˜¾ç¤º `enable_thinking (true)`
  - [ ] è¯·æ±‚ä½“åŒ…å« `"enable_thinking": true/false`

- [ ] **è±†åŒ…/DeepSeek**
  - [ ] é€‰æ‹©ä¸åŒæ¡£ä½ â†’ æ—¥å¿—æ˜¾ç¤º `reasoning_effort: medium`
  - [ ] è¯·æ±‚ä½“åŒ…å« `"reasoning_effort": "..."`

- [ ] **æ‰€æœ‰æ¨¡å‹**
  - [ ] æ¯ä¸ªæµå¼è¯·æ±‚éƒ½åŒ…å« `"stream_options": {"include_usage": true}`

## ğŸ“ ç›¸å…³æ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `/lib/ai.ts` | è¯·æ±‚æ‹¦æˆªå™¨ï¼Œæ³¨å…¥å‚æ•° |
| `/lib/db.ts` | æ•°æ®åº“æ¨¡å‹å®šä¹‰ |
| `/app/api/chat/route.ts` | èŠå¤© API è·¯ç”± |
| `/app/page.tsx` | ä¸»èŠå¤©ç•Œé¢ |
| `/components/chat/reasoning-effort-selector.tsx` | æ€è€ƒç¨‹åº¦é€‰æ‹©å™¨ |
| `/components/settings/model-form.tsx` | æ¨¡å‹é…ç½®è¡¨å• |
| `/app/settings/models/page.tsx` | æ¨¡å‹ç®¡ç†é¡µé¢ |

## ğŸš€ å¦‚ä½•æ·»åŠ æ–°çš„æ€è€ƒæ¨¡å‹

1. **æ›´æ–°æ•°æ®åº“**:
   ```sql
   UPDATE models 
   SET is_reasoning_model = 1,
       reasoning_type = 'binary',  -- æˆ– 'levels'
       default_reasoning_effort = 'enabled'  -- æˆ– 'medium'
   WHERE id = 'your-model-id';
   ```

2. **æ›´æ–° lib/db.ts**:
   ```typescript
   const PRESET_MODELS = [
     { 
       id: 'your-model-id', 
       provider_id: 'your-provider', 
       name: 'Model Name',
       is_reasoning: true, 
       reasoning_type: 'binary'  // æˆ– 'levels'
     },
   ];
   ```

3. **å¦‚æœæœ‰ç‰¹æ®Šå‚æ•°æ ¼å¼ï¼Œæ›´æ–° lib/ai.ts**:
   ```typescript
   switch (providerId) {
     case 'your-provider':
       bodyJson.your_custom_param = reasoningEffort;
       break;
   }
   ```

4. **åˆ·æ–°é¡µé¢éªŒè¯**

## ğŸ“ ç‰ˆæœ¬å†å²

- **2026-02-12**: 
  - æ·»åŠ åƒé—® (Qwen) æ”¯æŒï¼Œä½¿ç”¨ `enable_thinking` å‚æ•°
  - ä¸ºæ‰€æœ‰æ¨¡å‹æ·»åŠ  `stream_options.include_usage` ç”¨äºè®¡è´¹
  - æ›´æ–°æ–‡æ¡£ç»“æ„

- **2026-02-11**: 
  - æ™ºè°± AI (GLM) æ”¯æŒ `thinking` å‚æ•°
  - æ·»åŠ  `reasoning_type` å­—æ®µåŒºåˆ† binary/levels æ¨¡å¼
  - å®ç°åŠ¨æ€ UI é€‚é…
