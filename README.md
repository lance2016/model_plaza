# LLM Plaza

ğŸ¯ ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„å¤šæ¨¡å‹ AI èŠå¤©å¹³å°ï¼Œæ”¯æŒå¤šå®¶ä¸»æµ AI æä¾›å•†ï¼Œæä¾›ä¸°å¯Œçš„é…ç½®é€‰é¡¹å’Œæ€è€ƒæ¨¡å‹æ”¯æŒã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

### ğŸ¤– å¤šæ¨¡å‹æ”¯æŒ
- **OpenAI**: GPT-4o, GPT-4o Mini
- **Anthropic**: Claude Sonnet 4, Claude 3.5 Haiku
- **Google**: Gemini 2.0 Flash
- **DeepSeek**: DeepSeek Chat, DeepSeek Reasoner
- **æ™ºè°± AI (GLM)**: GLM-4-Flash, GLM-Zero-Preview
- **åƒé—® (Qwen)**: Qwen Plus, Qwen3-MAX
- **æœˆä¹‹æš—é¢ (Moonshot)**: Moonshot v1 8K
- **è±†åŒ… (Doubao)**: æ”¯æŒæ€è€ƒæ¨¡å‹

### ğŸ§  æ€è€ƒæ¨¡å‹æ”¯æŒ
- **Binary æ¨¡å¼** (GLM, Qwen): å¯ç”¨/ç¦ç”¨æ€è€ƒ
- **Levels æ¨¡å¼** (DeepSeek, Doubao): Minimal/Low/Medium/High å››æ¡£
- å®æ—¶æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
- å¯åŠ¨æ€åˆ‡æ¢æ€è€ƒç¨‹åº¦

### âš™ï¸ é«˜çº§å‚æ•°é…ç½®
- **ç³»ç»Ÿæç¤ºè¯**: è‡ªå®šä¹‰ AI è§’è‰²å’Œè¡Œä¸º
- **Temperature**: 0.0-2.0ï¼Œæ§åˆ¶è¾“å‡ºéšæœºæ€§
- **Max Tokens**: 256-32000ï¼Œé™åˆ¶ç”Ÿæˆé•¿åº¦
- **Top P**: 0.0-1.0ï¼Œæ ¸é‡‡æ ·æ§åˆ¶
- **Frequency Penalty**: -2.0-2.0ï¼Œå‡å°‘é‡å¤
- **Presence Penalty**: -2.0-2.0ï¼Œé¼“åŠ±æ–°è¯é¢˜

### ğŸ’¬ å¯¹è¯ç®¡ç†
- å¤šå¯¹è¯å†å²è®°å½•
- è‡ªåŠ¨ä¿å­˜å¯¹è¯
- ä¸€é”®æ¸…ç©ºå†å²
- å¿«é€Ÿåˆ‡æ¢å¯¹è¯

### ğŸ¨ ç”¨æˆ·ä½“éªŒ
- å“åº”å¼è®¾è®¡ï¼Œæ”¯æŒç§»åŠ¨ç«¯
- å®æ—¶æµå¼è¾“å‡º
- æš—è‰²æ¨¡å¼æ”¯æŒ
- ç›´è§‚çš„é…ç½®ç•Œé¢

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Node.js 18+
- npm æˆ– pnpm

### å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/llm-plaza.git
cd llm-plaza

# å®‰è£…ä¾èµ–
npm install

# åˆå§‹åŒ–æ•°æ®åº“
npm run seed
```

### é…ç½®

1. å¤åˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼š
```bash
cp .env.example .env.local
```

2. ç¼–è¾‘ `.env.local`ï¼Œé…ç½®ä½ éœ€è¦çš„ API Keys

3. æˆ–è€…åœ¨åº”ç”¨ä¸­é€šè¿‡è®¾ç½®é¡µé¢é…ç½® API Keys

### è¿è¡Œ

```bash
# å¼€å‘æ¨¡å¼
npm run dev

# ç”Ÿäº§æ„å»º
npm run build
npm start
```

æ‰“å¼€ [http://localhost:3000](http://localhost:3000) å¼€å§‹ä½¿ç”¨ã€‚

## ğŸ“– åŠŸèƒ½è¯¦è§£

è¯¦ç»†çš„é…ç½®è¯´æ˜å’Œä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒä¸‹æ–¹å„ä¸ªç« èŠ‚ã€‚

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
llm-plaza/
â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”œâ”€â”€ api/               # API è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ chat/         # èŠå¤© API
â”‚   â”‚   â”œâ”€â”€ models/       # æ¨¡å‹ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ providers/    # æä¾›å•†ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ conversations/# å¯¹è¯ç®¡ç†
â”‚   â”‚   â””â”€â”€ settings/     # è®¾ç½®ç®¡ç†
â”‚   â”œâ”€â”€ settings/         # è®¾ç½®é¡µé¢
â”‚   â”œâ”€â”€ layout.tsx        # æ ¹å¸ƒå±€
â”‚   â””â”€â”€ page.tsx          # ä¸»èŠå¤©é¡µé¢
â”œâ”€â”€ components/            # React ç»„ä»¶
â”‚   â”œâ”€â”€ chat/             # èŠå¤©ç›¸å…³ç»„ä»¶
â”‚   â”œâ”€â”€ settings/         # è®¾ç½®ç›¸å…³ç»„ä»¶
â”‚   â”œâ”€â”€ ui/               # UI åŸºç¡€ç»„ä»¶ (shadcn/ui)
â”‚   â””â”€â”€ sidebar.tsx       # ä¾§è¾¹æ 
â”œâ”€â”€ lib/                   # æ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ ai.ts             # AI SDK é›†æˆ
â”‚   â”œâ”€â”€ db.ts             # æ•°æ®åº“æ“ä½œ
â”‚   â””â”€â”€ utils.ts          # å·¥å…·å‡½æ•°
â”œâ”€â”€ data/                  # æ•°æ®å­˜å‚¨
â”‚   â””â”€â”€ llm-plaza.db      # SQLite æ•°æ®åº“
â””â”€â”€ public/               # é™æ€èµ„æº
```

## ğŸ”§ æŠ€æœ¯æ ˆ

- **æ¡†æ¶**: Next.js 15 (App Router)
- **UI**: React 19, TailwindCSS, shadcn/ui
- **AI SDK**: Vercel AI SDK 4.x
- **æ•°æ®åº“**: SQLite (better-sqlite3)
- **çŠ¶æ€ç®¡ç†**: React Hooks, SWR
- **æ ·å¼**: TailwindCSS, Radix UI
- **ç±»å‹**: TypeScript

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½è¯´æ˜

### æ€è€ƒæ¨¡å‹

æ”¯æŒä¸¤ç§æ€è€ƒæ¨¡å¼ï¼š

1. **Binary æ¨¡å¼** (æ™ºè°± GLM, åƒé—® Qwen)
   - å‚æ•°: `thinking: {type: 'enabled'/'disabled'}` æˆ– `enable_thinking: true/false`
   - UI: å¯ç”¨æ€è€ƒ / ç¦ç”¨æ€è€ƒ

2. **Levels æ¨¡å¼** (DeepSeek, è±†åŒ…)
   - å‚æ•°: `reasoning_effort: 'minimal'/'low'/'medium'/'high'`
   - UI: Minimal / Low / Medium / High

### é«˜çº§å‚æ•°

æ‰€æœ‰æµå¼è¯·æ±‚è‡ªåŠ¨æ·»åŠ  `stream_options: {include_usage: true}` ç”¨äºè®¡è´¹è¿½è¸ªã€‚

#### å‚æ•°è¯´æ˜

| å‚æ•° | èŒƒå›´ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| Temperature | 0.0-2.0 | 0.7 | æ§åˆ¶éšæœºæ€§ï¼Œä½å€¼æ›´ç¡®å®šï¼Œé«˜å€¼æ›´åˆ›é€  |
| Max Tokens | 256-32000 | 4096 | é™åˆ¶ç”Ÿæˆé•¿åº¦ |
| Top P | 0.0-1.0 | 1.0 | æ ¸é‡‡æ ·ï¼Œæ§åˆ¶è¯æ±‡å¤šæ ·æ€§ |
| Frequency Penalty | -2.0-2.0 | 0 | æ­£å€¼å‡å°‘é‡å¤ |
| Presence Penalty | -2.0-2.0 | 0 | æ­£å€¼é¼“åŠ±æ–°è¯é¢˜ |

## ğŸ› ï¸ å¼€å‘

### æ•°æ®åº“

ä½¿ç”¨ SQLite ä½œä¸ºæœ¬åœ°æ•°æ®åº“ï¼Œå­˜å‚¨ï¼š
- æä¾›å•†é…ç½®
- æ¨¡å‹é…ç½®
- å¯¹è¯å†å²
- åº”ç”¨è®¾ç½®

```bash
# é‡æ–°åˆå§‹åŒ–æ•°æ®åº“
npm run seed
```

### API è·¯ç”±

æ‰€æœ‰ API è·¯ç”±éƒ½åœ¨ `app/api` ç›®å½•ä¸‹ï¼š

- `POST /api/chat` - èŠå¤©æµå¼å“åº”
- `GET /api/models` - è·å–æ¨¡å‹åˆ—è¡¨
- `POST /api/models` - åˆ›å»ºæ¨¡å‹
- `PUT /api/models/[id]` - æ›´æ–°æ¨¡å‹
- `GET /api/providers` - è·å–æä¾›å•†åˆ—è¡¨
- `PUT /api/providers/[id]` - æ›´æ–°æä¾›å•†ï¼ˆé…ç½® API Keyï¼‰
- `GET /api/conversations` - è·å–å¯¹è¯åˆ—è¡¨
- `POST /api/conversations` - åˆ›å»ºå¯¹è¯
- `GET /api/settings` - è·å–è®¾ç½®
- `PUT /api/settings` - æ›´æ–°è®¾ç½®

## ğŸ¨ ä½¿ç”¨ç¤ºä¾‹

### åœºæ™¯ 1: ä»£ç åŠ©æ‰‹
```typescript
ç³»ç»Ÿæç¤ºè¯: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œæä¾›æ¸…æ™°ã€å‡†ç¡®çš„ä»£ç å’Œè§£é‡Šã€‚"
Temperature: 0.2
Max Tokens: 4096
æ€è€ƒæ¨¡å¼: æ ¹æ®éœ€è¦é€‰æ‹©
```

### åœºæ™¯ 2: åˆ›æ„å†™ä½œ
```typescript
ç³»ç»Ÿæç¤ºè¯: "ä½ æ˜¯ä¸€ä½å¯Œæœ‰æƒ³è±¡åŠ›çš„ä½œå®¶ï¼Œå–„äºåˆ›ä½œå¼•äººå…¥èƒœçš„æ•…äº‹ã€‚"
Temperature: 1.0
Max Tokens: 8192
Frequency Penalty: 0.5
Presence Penalty: 0.3
```

## ğŸ”§ è°ƒè¯•

æ‰€æœ‰è¯·æ±‚éƒ½ä¼šåœ¨ç»ˆç«¯æ‰“å°è¯¦ç»†æ—¥å¿—ï¼š

```
=== AI SDK HTTP Request ===
Model ID: qwen-plus
Chat Config: { systemPrompt: '...', temperature: 0.7, ... }
Stream options: { temperature: 0.7, maxTokens: 4096, ... }
```

## ğŸ“ å¾…åŠäº‹é¡¹

- [ ] é…ç½®é¢„è®¾ç®¡ç†
- [ ] å›¾ç‰‡ä¸Šä¼ å’Œå¤šæ¨¡æ€è¾“å…¥
- [ ] å¯¼å‡ºå¯¹è¯ä¸º Markdown
- [ ] Docker éƒ¨ç½²
- [ ] ç”¨æˆ·è®¤è¯

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

---

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æ Issueï¼
